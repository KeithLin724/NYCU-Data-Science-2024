{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "## Written By KYLiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader , random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# speed up \n",
    "from torch.cuda.amp import GradScaler , autocast\n",
    "\n",
    "# other sampler\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cuda\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cuda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据的 transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=0,translate=(0.05,0.05)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 测试数据的 transforms\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_folder_path , boo_folder_path = \"./data/HOT\" , \"./data/BOO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dataset size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55231</span>, train size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41423</span>, val size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13808</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dataset size: \u001b[1;36m55231\u001b[0m, train size: \u001b[1;36m41423\u001b[0m, val size: \u001b[1;36m13808\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"./data\"\n",
    "dataset = ImageFolder(dataset_path)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.75 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "print(f\"dataset size: {dataset_size}, train size: {train_size}, val size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_data_images = [os.path.join(hot_folder_path , item) for item in os.listdir(hot_folder_path)]\n",
    "boo_data_images = [os.path.join(boo_folder_path , item) for item in os.listdir(boo_folder_path)]\n",
    "\n",
    "hot_images_size  , boo_images_size = len(hot_data_images) , len(boo_data_images)\n",
    "\n",
    "total_images_size = hot_images_size + boo_images_size \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_length = len(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">hot weight: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4789497307001795</span> , boo weight: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6263296364337393</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "hot weight: \u001b[1;36m2.4789497307001795\u001b[0m , boo weight: \u001b[1;36m0.6263296364337393\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "hot_weight , boo_weight = total_images_size / (classes_length*hot_images_size) , total_images_size / (classes_length* boo_images_size)\n",
    "# BOO 0 , HOT 0\n",
    "sample_weight = torch.Tensor([boo_weight , hot_weight])\n",
    "\n",
    "print(f\"hot weight: {hot_weight} , boo weight: {boo_weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset , val_dataset = random_split(dataset , [train_size , val_size])\n",
    "\n",
    "train_dataset.dataset.transform = transform_train\n",
    "val_dataset.dataset.transform = transform_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,\n",
    "                        #   sampler=WeightedRandomSampler([boo_weight , hot_weight], num_samples=len(dataset) , replacement=True), # include shuffle=True\n",
    "                          batch_size=TRAIN_BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          )\n",
    "\n",
    "test_loader = DataLoader(val_dataset,\n",
    "                         batch_size=TEST_BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"./model\" , \"mobileNet_v3_test_v4_sampler.pth\")\n",
    "\n",
    "\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "num_features = model.classifier[-1].in_features\n",
    "# output only two class \n",
    "model.classifier[-1] = nn.Linear(num_features , 2)\n",
    "\n",
    "model = model.to(device=device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # weight=sample_weight.to(device)\n",
    "# criterion = nn.BCEWithLogitsLoss() # weight=sample_weight.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters() , lr=3e-4 ,  weight_decay=0.0001)\n",
    "# optimizer = optim.SGD(model.parameters() ,lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/1295 [00:00<?, ?batch/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1467e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5732e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0849e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.1231e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.4429e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.0679e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3990e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.2392e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.6485e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.5422e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0239e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.2108e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6.3972e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.7515e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0651e-01</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.6670e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.3831e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0727e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4460e-04</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2527e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.2634e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.0741e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.2943e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.1185e-04</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1559e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.3588e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.5980e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8.2214e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2064e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.5137e-01</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.0727e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1376e-04</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.3678e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.2670e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.5320e-04</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1230e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-5.1804e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.3280e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6296e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.8051e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0366e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.8060e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.1716e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.1498e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.3422e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.8473e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1452e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.9072e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-4.7264e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.7557e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-7.7667e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.2381e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.6866e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-6.8970e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.7351e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3864e-04</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2611e-02</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1429e-02</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.2817e-04</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.4833e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-8.1024e-03</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3590e-03</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-3.3455e-03</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.1329e-03</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">torch</span>.float16,\n",
       "       <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">AddmmBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.1467e-02\u001b[0m, \u001b[1;36m-1.5732e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.0849e-02\u001b[0m, \u001b[1;36m-5.1231e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-2.4429e-02\u001b[0m, \u001b[1;36m-7.0679e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.3990e-03\u001b[0m,  \u001b[1;36m9.2392e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-7.6485e-03\u001b[0m, \u001b[1;36m-6.5422e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.0239e-02\u001b[0m, \u001b[1;36m-1.2108e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m6.3972e-03\u001b[0m,  \u001b[1;36m7.7515e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.0651e-01\u001b[0m, \u001b[1;36m-3.6670e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-4.3831e-03\u001b[0m, \u001b[1;36m-1.0727e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.4460e-04\u001b[0m,  \u001b[1;36m1.2527e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.2634e-02\u001b[0m, \u001b[1;36m-4.0741e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-6.2943e-03\u001b[0m, \u001b[1;36m-3.1185e-04\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.1559e-02\u001b[0m, \u001b[1;36m-3.3588e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-3.5980e-02\u001b[0m, \u001b[1;36m-8.2214e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-2.2064e-02\u001b[0m, \u001b[1;36m-1.5137e-01\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-3.0727e-03\u001b[0m,  \u001b[1;36m3.1376e-04\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m4.3678e-03\u001b[0m, \u001b[1;36m-7.2670e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m2.5320e-04\u001b[0m, \u001b[1;36m-1.1230e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-5.1804e-03\u001b[0m,  \u001b[1;36m7.3280e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.6296e-02\u001b[0m, \u001b[1;36m-1.8051e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-1.0366e-03\u001b[0m,  \u001b[1;36m5.8060e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m7.1716e-03\u001b[0m,  \u001b[1;36m5.1498e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m2.3422e-02\u001b[0m, \u001b[1;36m-2.8473e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.1452e-02\u001b[0m, \u001b[1;36m-4.9072e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-4.7264e-03\u001b[0m, \u001b[1;36m-2.7557e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-7.7667e-03\u001b[0m,  \u001b[1;36m4.2381e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m7.6866e-03\u001b[0m, \u001b[1;36m-6.8970e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-2.7351e-03\u001b[0m, \u001b[1;36m-1.3864e-04\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m \u001b[1;36m1.2611e-02\u001b[0m, \u001b[1;36m-1.1429e-02\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-2.2817e-04\u001b[0m,  \u001b[1;36m9.4833e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-8.1024e-03\u001b[0m, \u001b[1;36m-1.3590e-03\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m-3.3455e-03\u001b[0m,  \u001b[1;36m8.1329e-03\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float16,\n",
       "       \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mAddmmBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/1295 [00:01<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_outputs)\n\u001b[1;32m---> 25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# use scaler update  \u001b[39;00m\n\u001b[0;32m     28\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\Code\\Visual Code\\Python\\NYCU Data Science 2024\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Code\\Visual Code\\Python\\NYCU Data Science 2024\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Code\\Visual Code\\Python\\NYCU Data Science 2024\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Code\\Visual Code\\Python\\NYCU Data Science 2024\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:3197\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m-> 3197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[1;31mValueError\u001b[0m: Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 2]))"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()\n",
    "old_test_acc = -1\n",
    "for epoch in range(TRAIN_EPOCH):\n",
    "    start_time = time()\n",
    "    \n",
    "    \n",
    "    train_acc , test_acc = 0 , 0 \n",
    "    # training\n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader , unit=\"batch\" , desc=\"Training...\") as t_epoch:\n",
    "        for inputs , labels in t_epoch:\n",
    "            \n",
    "            # in cuda\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs , labels_gpu = inputs.to(device) , labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            with autocast():\n",
    "                model_outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(model_outputs.float() , labels_gpu)\n",
    "                \n",
    "            # use scaler update  \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "                \n",
    "            \n",
    "            # in cpu\n",
    "            model_outputs = model_outputs.cpu()\n",
    "            # dim is one , get array \n",
    "            train_pred = torch.max(model_outputs , 1).indices\n",
    "            # how many is same \n",
    "            train_acc += int(torch.sum(train_pred == labels))\n",
    "            \n",
    "        \n",
    "        # get epoch train acc \n",
    "        ep_train_acc = train_acc / train_size\n",
    "    \n",
    "    # lock model \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # validation\n",
    "        with tqdm(test_loader , unit=\"batch\" , desc=\"Testing...\") as test_epoch:\n",
    "            for inputs , labels in test_epoch:\n",
    "                # in cuda\n",
    "                torch.cuda.empty_cache()\n",
    "                inputs , labels_gpu = inputs.to(device) , labels.to(device)\n",
    "                test_prob = model(inputs)\n",
    "                \n",
    "                # in cpu\n",
    "                test_prob = test_prob.cpu()\n",
    "                test_pred = torch.max(test_prob , 1).indices\n",
    "                test_acc += int(torch.sum(test_pred == labels))\n",
    "                \n",
    "        ep_test_acc = test_acc / val_size\n",
    "        # ep_test_acc = test_acc / len(dataset)\n",
    "                \n",
    "    \n",
    "    end_time = time()\n",
    "    duration = (end_time - start_time) / 60\n",
    "    print(f\"Time: {duration}, Loss: {loss:.2f}\\nTrain_acc: {ep_train_acc*100 :.2f}, Test_acc: {ep_test_acc*100 :.2f}\")\n",
    "    \n",
    "    if ep_test_acc > old_test_acc:\n",
    "        torch.save(model.state_dict() , MODEL_PATH)\n",
    "        old_test_acc = ep_test_acc\n",
    "        print(f\"update new model, new {ep_test_acc*100 :.2f} , save in {MODEL_PATH}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model.state_dict() , MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

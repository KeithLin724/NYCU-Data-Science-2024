{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "## Written By KYLiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader , random_split\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# speed up \n",
    "from torch.cuda.amp import GradScaler , autocast\n",
    "\n",
    "\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cuda\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cuda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据的 transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomAffine(degrees=0,translate=(0.05,0.05)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 测试数据的 transforms\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dataset size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55231</span>, train size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41423</span>, val size: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13808</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "dataset size: \u001b[1;36m55231\u001b[0m, train size: \u001b[1;36m41423\u001b[0m, val size: \u001b[1;36m13808\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_path = \"./data\"\n",
    "dataset = ImageFolder(dataset_path)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.75 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "print(f\"dataset size: {dataset_size}, train size: {train_size}, val size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset , val_dataset = random_split(dataset , [train_size , val_size])\n",
    "\n",
    "train_dataset.dataset.transform = transform_train\n",
    "val_dataset.dataset.transform = transform_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset , batch_size=TRAIN_BATCH_SIZE , shuffle=True)\n",
    "test_loader = DataLoader(val_dataset , batch_size=TEST_BATCH_SIZE , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"./model\" , \"mobileNet_v3_test.pth\")\n",
    "\n",
    "\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "num_features = model.classifier[-1].in_features\n",
    "# output only two class \n",
    "model.classifier[-1] = nn.Linear(num_features , 2)\n",
    "\n",
    "model = model.to(device=device)\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters() , lr=3e-4 ,  weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EPOCH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 1295/1295 [21:39<00:00,  1.00s/batch]\n",
      "Testing...: 100%|██████████| 432/432 [07:11<00:00,  1.00batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.85016630490621</span>, Loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.82</span>\n",
       "Train_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.62</span>, Test_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.19</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time: \u001b[1;36m28.85016630490621\u001b[0m, Loss: \u001b[1;36m0.82\u001b[0m\n",
       "Train_acc: \u001b[1;36m79.62\u001b[0m, Test_acc: \u001b[1;36m80.19\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 1295/1295 [21:30<00:00,  1.00batch/s]\n",
      "Testing...: 100%|██████████| 432/432 [07:18<00:00,  1.01s/batch]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.809700179100037</span>, Loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.51</span>\n",
       "Train_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.68</span>, Test_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.24</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time: \u001b[1;36m28.809700179100037\u001b[0m, Loss: \u001b[1;36m0.51\u001b[0m\n",
       "Train_acc: \u001b[1;36m79.68\u001b[0m, Test_acc: \u001b[1;36m80.24\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 1295/1295 [28:42<00:00,  1.33s/batch]\n",
      "Testing...: 100%|██████████| 432/432 [07:55<00:00,  1.10s/batch]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Time: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.629302438100176</span>, Loss: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.39</span>\n",
       "Train_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">79.74</span>, Test_acc: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.18</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Time: \u001b[1;36m36.629302438100176\u001b[0m, Loss: \u001b[1;36m0.39\u001b[0m\n",
       "Train_acc: \u001b[1;36m79.74\u001b[0m, Test_acc: \u001b[1;36m80.18\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(TRAIN_EPOCH):\n",
    "    start_time = time()\n",
    "    \n",
    "    \n",
    "    train_acc , test_acc = 0 , 0 \n",
    "    # training\n",
    "    model.train()\n",
    "    \n",
    "    with tqdm(train_loader , unit=\"batch\" , desc=\"Training...\") as t_epoch:\n",
    "        for inputs , labels in t_epoch:\n",
    "            # in cuda\n",
    "            torch.cuda.empty_cache()\n",
    "            inputs , labels_gpu = inputs.to(device) , labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            with autocast():\n",
    "                model_outputs = model(inputs)\n",
    "                loss = criterion(model_outputs , labels_gpu)\n",
    "                \n",
    "            # use scaler update  \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "                \n",
    "            \n",
    "            # in cpu\n",
    "            model_outputs = model_outputs.cpu()\n",
    "            # dim is one , get array \n",
    "            train_pred = torch.max(model_outputs , 1).indices\n",
    "            # how many is same \n",
    "            train_acc += int(torch.sum(train_pred == labels))\n",
    "        \n",
    "        # get epoch train acc \n",
    "        ep_train_acc = train_acc / train_size\n",
    "    \n",
    "    # lock model \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # validation\n",
    "        with tqdm(test_loader , unit=\"batch\" , desc=\"Testing...\") as test_epoch:\n",
    "            for inputs , labels in test_epoch:\n",
    "                # in cuda\n",
    "                torch.cuda.empty_cache()\n",
    "                inputs , labels_gpu = inputs.to(device) , labels.to(device)\n",
    "                test_prob = model(inputs)\n",
    "                \n",
    "                # in cpu\n",
    "                test_prob = test_prob.cpu()\n",
    "                test_pred = torch.max(test_prob , 1).indices\n",
    "                test_acc += int(torch.sum(test_pred == labels))\n",
    "                \n",
    "        ep_test_acc = test_acc / val_size\n",
    "                \n",
    "    \n",
    "    end_time = time()\n",
    "    duration = (end_time - start_time) / 60\n",
    "    print(f\"Time: {duration}, Loss: {loss:.2f}\\nTrain_acc: {ep_train_acc*100 :.2f}, Test_acc: {ep_test_acc*100 :.2f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict() , MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

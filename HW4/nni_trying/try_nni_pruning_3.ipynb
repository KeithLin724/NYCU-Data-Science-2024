{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# from torch.utils.data import ConcatDataset\n",
    "\n",
    "import nni\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "# from transformers import BertTokenizerFast, DataCollatorWithPadding, BertForSequenceClassification, EvalPrediction\n",
    "# from transformers.trainer import Trainer\n",
    "# from transformers.training_args import TrainingArguments\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorForSeq2Seq , \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    Seq2SeqTrainer,\n",
    "    # t5 \n",
    "    T5TokenizerFast,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from rich import print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TALib import TALib\n",
    "ta_lib = TALib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained_model_name_or_path: str = TALib.CHECKPOINT, task_name: str = None):\n",
    "    # is_regression = task_name == 'stsb'\n",
    "    # num_labels = 1 if is_regression else (3 if task_name == 'mnli' else 2)\n",
    "    # model = BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path, num_labels=num_labels)\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(TALib.TK_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(task_name: str = None , tokenizer: T5TokenizerFast = None, cache_dir: str = None):\n",
    "    billsum = load_dataset(\"billsum\", split=\"train\")\n",
    "    preprocess_function = TALib.preprocess_function_pass_tokenizer(tokenizer)\n",
    "    \n",
    "    tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "    \n",
    "    billsum_test = load_dataset(\"billsum\", split=\"test\")\n",
    "    tokenized_billsum_test = billsum_test.map(preprocess_function, batched=True)\n",
    "    \n",
    "    return tokenized_billsum , tokenized_billsum_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_traced_trainer(model:T5ForConditionalGeneration, task_name = None, load_best_model_at_end=False):\n",
    "   \n",
    "    metric = evaluate.load(\"rouge\")\n",
    "\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(TALib.TK_ckpt)\n",
    "    \n",
    "    compute_metrics = TALib.compute_metrics_pass_tokenizer(tokenizer)\n",
    "    \n",
    "    train_dataset, validation_datasets = prepare_datasets(None, tokenizer, None)\n",
    "    \n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=TALib.CHECKPOINT)\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"TA_billsum_model\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        weight_decay=0.01,  # Assuming you still want weight decay as it wasn't mentioned to remove\n",
    "        save_total_limit=3,  # Assuming to maintain the save limit as before\n",
    "        num_train_epochs=4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "        fp16=True,  # You mentioned \"Native AMP\" for mixed precision training which is generally enabled by setting fp16=True in Transformers\n",
    "        logging_steps=10,  # Assuming to keep the logging frequency as before\n",
    "        predict_with_generate=True,\n",
    "    )\n",
    "    \n",
    "    trainer = nni.trace(Seq2SeqTrainer)(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset[\"train\"],\n",
    "        eval_dataset=train_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetuning_model(task_name: str , state_dict_path: str):\n",
    "    model = build_model(TALib.TK_ckpt, None)\n",
    "    if Path(state_dict_path).exists():\n",
    "        model.load_state_dict(torch.load(state_dict_path))\n",
    "    else:\n",
    "        trainer = prepare_traced_trainer(model, None, True)\n",
    "        trainer.train()\n",
    "        torch.save(model.state_dict(), state_dict_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path('./output/t5_finetuned').mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSeq2SeqLM.from_pretrained(TALib.CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'./output/t5_finetuned/ta_t5.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skip_exec = False \n",
    "model_name = \"ta_t5\"\n",
    "if not skip_exec:\n",
    "    Path('./output/bert_finetuned').mkdir(exist_ok=True, parents=True)\n",
    "    model = build_finetuning_model(None, f'./output/t5_finetuned/{model_name}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.distillation import DynamicLayerwiseDistiller, Adaptive1dLayerwiseDistiller\n",
    "from nni.compression.utils import TransformersEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (565429998.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    'link': ,\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "def dynamic_distiller(student_model: T5ForConditionalGeneration,\n",
    "                      teacher_model: T5ForConditionalGeneration,\n",
    "                      student_trainer: Seq2SeqTrainer):\n",
    "    \n",
    "    layer_num = len(student_model.bert.encoder.layer)\n",
    "    \n",
    "    config_list = [{\n",
    "        'op_names': [\n",
    "            f'bert.encoder.layer.{i}'\n",
    "        ],\n",
    "        # 'link': [f'bert.encoder.layer.{j}' for j in range(i, layer_num)],\n",
    "        'link': \"auto\",\n",
    "        'lambda': 0.9,\n",
    "        'apply_method': 'mse',\n",
    "    } for i in range(layer_num)]\n",
    "\n",
    "\n",
    "    evaluator = TransformersEvaluator(student_trainer)\n",
    "\n",
    "    def teacher_predict(batch, teacher_model):\n",
    "        return teacher_model(**batch)\n",
    "\n",
    "    return DynamicLayerwiseDistiller(student_model, config_list, evaluator, teacher_model, teacher_predict, origin_loss_lambda=0.1)\n",
    "\n",
    "\n",
    "def dynamic_distillation(student_model: T5ForConditionalGeneration, \n",
    "                         teacher_model: T5ForConditionalGeneration,\n",
    "                         max_steps: int | None, max_epochs: int | None):\n",
    "    \n",
    "    student_trainer = prepare_traced_trainer(student_model, None, True)\n",
    "\n",
    "    ori_teacher_device = teacher_model.device\n",
    "    training = teacher_model.training\n",
    "    teacher_model.to(student_trainer.args.device).eval()\n",
    "\n",
    "    distiller = dynamic_distiller(student_model, teacher_model, student_trainer)\n",
    "    distiller.compress(max_steps, max_epochs)\n",
    "    distiller.unwrap_model()\n",
    "\n",
    "    teacher_model.to(ori_teacher_device).train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

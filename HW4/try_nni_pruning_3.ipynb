{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "# from torch.utils.data import ConcatDataset\n",
    "\n",
    "import nni\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "# from transformers import BertTokenizerFast, DataCollatorWithPadding, BertForSequenceClassification, EvalPrediction\n",
    "# from transformers.trainer import Trainer\n",
    "# from transformers.training_args import TrainingArguments\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    DataCollatorForSeq2Seq , \n",
    "    AutoModelForSeq2SeqLM, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    Seq2SeqTrainer,\n",
    "    # t5 \n",
    "    T5TokenizerFast,\n",
    "    T5ForConditionalGeneration\n",
    ")\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "from rich import print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TALib import TALib\n",
    "ta_lib = TALib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained_model_name_or_path: str = TALib.CHECKPOINT, task_name: str = None):\n",
    "    # is_regression = task_name == 'stsb'\n",
    "    # num_labels = 1 if is_regression else (3 if task_name == 'mnli' else 2)\n",
    "    # model = BertForSequenceClassification.from_pretrained(pretrained_model_name_or_path, num_labels=num_labels)\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(pretrained_model_name_or_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(TALib.TK_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(task_name: str = None , tokenizer: T5TokenizerFast = None, cache_dir: str = None):\n",
    "    billsum = load_dataset(\"billsum\", split=\"train\")\n",
    "    preprocess_function = TALib.preprocess_function_pass_tokenizer(tokenizer)\n",
    "    \n",
    "    tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "    \n",
    "    billsum_test = load_dataset(\"billsum\", split=\"test\")\n",
    "    tokenized_billsum_test = billsum_test.map(preprocess_function, batched=True)\n",
    "    \n",
    "    return tokenized_billsum , tokenized_billsum_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_traced_trainer(model:T5ForConditionalGeneration, task_name = None, load_best_model_at_end=False):\n",
    "   \n",
    "    metric = evaluate.load(\"rouge\")\n",
    "\n",
    "    tokenizer = T5TokenizerFast.from_pretrained(TALib.TK_ckpt)\n",
    "    \n",
    "    compute_metrics = TALib.compute_metrics_pass_tokenizer(tokenizer)\n",
    "    \n",
    "    train_dataset, validation_datasets = prepare_datasets(None, tokenizer, None)\n",
    "    \n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=TALib.CHECKPOINT)\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=\"TA_billsum_model\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=2,\n",
    "        per_device_eval_batch_size=2,\n",
    "        weight_decay=0.01,  # Assuming you still want weight decay as it wasn't mentioned to remove\n",
    "        save_total_limit=3,  # Assuming to maintain the save limit as before\n",
    "        num_train_epochs=4,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=42,\n",
    "        fp16=True,  # You mentioned \"Native AMP\" for mixed precision training which is generally enabled by setting fp16=True in Transformers\n",
    "        logging_steps=10,  # Assuming to keep the logging frequency as before\n",
    "        predict_with_generate=True,\n",
    "    )\n",
    "    \n",
    "    trainer = nni.trace(Seq2SeqTrainer)(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset[\"train\"],\n",
    "        eval_dataset=train_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_finetuning_model(task_name: str , state_dict_path: str):\n",
    "    model = build_model(TALib.TK_ckpt, None)\n",
    "    if Path(state_dict_path).exists():\n",
    "        model.load_state_dict(torch.load(state_dict_path))\n",
    "    else:\n",
    "        trainer = prepare_traced_trainer(model, None, True)\n",
    "        trainer.train()\n",
    "        torch.save(model.state_dict(), state_dict_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path('./output/t5_finetuned').mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSeq2SeqLM.from_pretrained(TALib.CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'./output/t5_finetuned/ta_t5.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skip_exec = False \n",
    "model_name = \"ta_t5\"\n",
    "if not skip_exec:\n",
    "    Path('./output/t5_finetuned').mkdir(exist_ok=True, parents=True)\n",
    "    model = build_finetuning_model(None, f'./output/t5_finetuned/{model_name}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.distillation import DynamicLayerwiseDistiller, Adaptive1dLayerwiseDistiller\n",
    "from nni.compression.utils import TransformersEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T5ForConditionalGeneration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdynamic_distiller\u001b[39m(student_model: \u001b[43mT5ForConditionalGeneration\u001b[49m,\n\u001b[1;32m      2\u001b[0m                       teacher_model: T5ForConditionalGeneration,\n\u001b[1;32m      3\u001b[0m                       student_trainer: Seq2SeqTrainer):\n\u001b[1;32m      5\u001b[0m     block_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(student_model\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mblock)\n\u001b[1;32m      7\u001b[0m     config_encode_list \u001b[38;5;241m=\u001b[39m [{\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mop_names\u001b[39m\u001b[38;5;124m'\u001b[39m: [\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoder.block.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.layer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapply_method\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     } \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(block_num)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T5ForConditionalGeneration' is not defined"
     ]
    }
   ],
   "source": [
    "def dynamic_distiller(student_model: T5ForConditionalGeneration,\n",
    "                      teacher_model: T5ForConditionalGeneration,\n",
    "                      student_trainer: Seq2SeqTrainer):\n",
    "    \n",
    "    block_num = len(student_model.encoder.block)\n",
    "    \n",
    "    config_encode_list = [{\n",
    "        'op_names': [\n",
    "            f'encoder.block.{i}.layer',\n",
    "            \n",
    "        ],\n",
    "        'link': \"auto\",\n",
    "        'lambda': 0.9,\n",
    "        'apply_method': 'mse',\n",
    "    } for i in range(block_num)]\n",
    "    \n",
    "    config_decode_list = [{\n",
    "        'op_names': [\n",
    "            f'decode.block.{i}.layer',\n",
    "            \n",
    "        ],\n",
    "        'link': \"auto\",\n",
    "        'lambda': 0.9,\n",
    "        'apply_method': 'mse',\n",
    "    } for i in range(block_num)]\n",
    "    \n",
    "    config_list = config_encode_list + config_decode_list\n",
    "\n",
    "\n",
    "    evaluator = TransformersEvaluator(student_trainer)\n",
    "\n",
    "    def teacher_predict(batch, teacher_model):\n",
    "        return teacher_model(**batch)\n",
    "\n",
    "    return DynamicLayerwiseDistiller(student_model, config_list, evaluator, teacher_model, teacher_predict, origin_loss_lambda=0.1)\n",
    "\n",
    "\n",
    "def dynamic_distillation(student_model: T5ForConditionalGeneration, \n",
    "                         teacher_model: T5ForConditionalGeneration,\n",
    "                         max_steps: int | None, max_epochs: int | None):\n",
    "    \n",
    "    student_trainer = prepare_traced_trainer(student_model, None, True)\n",
    "\n",
    "    ori_teacher_device = teacher_model.device\n",
    "    training = teacher_model.training\n",
    "    teacher_model.to(student_trainer.args.device).eval()\n",
    "\n",
    "    distiller = dynamic_distiller(student_model, teacher_model, student_trainer)\n",
    "    distiller.compress(max_steps, max_epochs)\n",
    "    distiller.unwrap_model()\n",
    "\n",
    "    teacher_model.to(ori_teacher_device).train(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_distiller(student_model: T5ForConditionalGeneration,\n",
    "                    teacher_model: T5ForConditionalGeneration,\n",
    "                    student_trainer: Seq2SeqTrainer):\n",
    "    block_num = len(student_model.encoder.block)\n",
    "    \n",
    "    config_encode_list = [{\n",
    "        'op_names': [\n",
    "            f'encoder.block.{i}.layer',\n",
    "            \n",
    "        ],\n",
    "        'link': \"auto\",\n",
    "        'lambda': 0.9,\n",
    "        'apply_method': 'mse',\n",
    "    } for i in range(block_num)]\n",
    "    \n",
    "    config_decode_list = [{\n",
    "        'op_names': [\n",
    "            f'decode.block.{i}.layer',\n",
    "            \n",
    "        ],\n",
    "        'link': \"auto\",\n",
    "        'lambda': 0.9,\n",
    "        'apply_method': 'mse',\n",
    "    } for i in range(block_num)]\n",
    "    \n",
    "    config_list = config_encode_list + config_decode_list\n",
    "\n",
    "\n",
    "    evaluator = TransformersEvaluator(student_trainer)\n",
    "\n",
    "    def teacher_predict(batch, teacher_model):\n",
    "        return teacher_model(**batch)\n",
    "\n",
    "    return Adaptive1dLayerwiseDistiller(student_model, config_list, evaluator, teacher_model, teacher_predict, origin_loss_lambda=0.1)\n",
    "\n",
    "\n",
    "def adapt_distillation(student_model: T5ForConditionalGeneration,\n",
    "                       teacher_model: T5ForConditionalGeneration,\n",
    "                       max_steps: int | None, max_epochs: int | None):\n",
    "    student_trainer = prepare_traced_trainer(student_model, None, True)\n",
    "\n",
    "    ori_teacher_device = teacher_model.device\n",
    "    training = teacher_model.training\n",
    "    teacher_model.to(student_trainer.args.device).eval()\n",
    "\n",
    "    distiller = adapt_distiller(student_model, teacher_model, student_trainer)\n",
    "    dummy_input = (torch.randint(0, 10000, [8, 128]), torch.randint(0, 2, [8, 128]), torch.randint(0, 2, [8, 128]))\n",
    "    dummy_input = [_.to(student_trainer.args.device) for _ in dummy_input]\n",
    "    distiller.track_forward(*dummy_input)\n",
    "\n",
    "    distiller.compress(max_steps, max_epochs)\n",
    "    distiller.unwrap_model()\n",
    "\n",
    "    teacher_model.to(ori_teacher_device).train(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pruning import MovementPruner\n",
    "from nni.compression.speedup import ModelSpeedup\n",
    "from nni.compression.utils.external.external_replacer import TransformersAttentionReplacer\n",
    "\n",
    "\n",
    "def pruning_attn():\n",
    "    Path('./output/t5_finetuned/').mkdir(parents=True, exist_ok=True)\n",
    "    model = build_finetuning_model(None, f'./output/t5_finetuned/{model_name}.bin')\n",
    "    trainer = prepare_traced_trainer(model, None)\n",
    "    evaluator = TransformersEvaluator(trainer)\n",
    "\n",
    "    config_list = [{\n",
    "        'op_types': ['Linear'],\n",
    "        'op_names_re': [\"(encoder|decoder)\\.block\\.[0-9]+\\.layer\\.[0-9]+\\.SelfAttention\\.*\"],\n",
    "        'sparse_threshold': 0.1,\n",
    "        'granularity': [64, 64]\n",
    "    }]\n",
    "\n",
    "    pruner = MovementPruner(model, config_list, evaluator, warmup_step=9000, cooldown_begin_step=36000, regular_scale=10)\n",
    "    pruner.compress(None, 4)\n",
    "    pruner.unwrap_model()\n",
    "\n",
    "    masks = pruner.get_masks()\n",
    "    Path('./output/pruning_t5/').mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(masks, './output/pruning_t5/attn_masks.pth')\n",
    "    torch.save(model, './output/pruning_t5/attn_masked_model.pth')\n",
    "\n",
    "\n",
    "if not skip_exec:\n",
    "    pruning_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speedup_attn():\n",
    "    model = torch.load('./output/pruning_t5/attn_masked_model.pth', map_location='cpu')\n",
    "    masks = torch.load('./output/pruning_t5/attn_masks.pth', map_location='cpu')\n",
    "    dummy_input = (torch.randint(0, 10000, [8, 128]), torch.randint(0, 2, [8, 128]), torch.randint(0, 2, [8, 128]))\n",
    "    replacer = TransformersAttentionReplacer(model)\n",
    "    ModelSpeedup(model, dummy_input, masks, customized_replacers=[replacer]).speedup_model()\n",
    "\n",
    "    # finetuning\n",
    "    teacher_model = build_finetuning_model(None, f'./output/t5_finetuned/{model_name}.bin')\n",
    "    dynamic_distillation(model, teacher_model, None, 3)\n",
    "    torch.save(model, './output/pruning_t5/attn_pruned_model.pth')\n",
    "\n",
    "\n",
    "if not skip_exec:\n",
    "    speedup_attn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pruning import TaylorPruner, AGPPruner\n",
    "from transformers.models.bert.modeling_bert import BertLayer\n",
    "from transformers.models.t5.modeling_t5 import T5LayerFF\n",
    "\n",
    "\n",
    "def pruning_ffn():\n",
    "    model: T5ForConditionalGeneration = torch.load('./output/pruning_t5/attn_pruned_model.pth')\n",
    "    teacher_model: T5ForConditionalGeneration = build_finetuning_model(None, f'./output/t5_finetuned/{model_name}.bin')\n",
    "    # create ffn config list, here simply use a linear function related to the number of retained heads to determine the sparse ratio\n",
    "    config_list = []\n",
    "    for name, module in model.named_modules():\n",
    "        # if isinstance(module, BertLayer):\n",
    "        #     retained_head_num = module.attention.self.num_attention_heads\n",
    "        #     ori_head_num = len(module.attention.pruned_heads) + retained_head_num\n",
    "        #     ffn_sparse_ratio = 1 - retained_head_num / ori_head_num / 2\n",
    "        #     config_list.append({'op_names': [f'{name}.intermediate.dense'], 'sparse_ratio': ffn_sparse_ratio})\n",
    "        if isinstance(module, T5LayerFF):\n",
    "            retained_head_num = 1  # 假设保留一个头部\n",
    "            ori_head_num = 2  # 假设原始有两个头部\n",
    "            ffn_sparse_ratio = 1 - retained_head_num / ori_head_num / 2\n",
    "            config_list.append({'op_names': [f'{name}.DenseReluDense.wo'], 'sparse_ratio': ffn_sparse_ratio})\n",
    "\n",
    "    trainer = prepare_traced_trainer(model, None)\n",
    "    teacher_model.eval().to(trainer.args.device)\n",
    "    # create a distiller for restoring the accuracy\n",
    "    distiller = dynamic_distiller(model, teacher_model, trainer)\n",
    "    # fusion compress: TaylorPruner + DynamicLayerwiseDistiller\n",
    "    taylor_pruner = TaylorPruner.from_compressor(distiller, config_list, 1000)\n",
    "    # fusion compress: AGPPruner(TaylorPruner) + DynamicLayerwiseDistiller\n",
    "    agp_pruner = AGPPruner(taylor_pruner, 1000, 36)\n",
    "    agp_pruner.compress(None, 3)\n",
    "    agp_pruner.unwrap_model()\n",
    "    distiller.unwrap_teacher_model()\n",
    "\n",
    "    masks = agp_pruner.get_masks()\n",
    "    Path('./output/pruning_t5/').mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(masks, './output/pruning_t5/ffn_masks.pth')\n",
    "    torch.save(model, './output/pruning_t5/ffn_masked_model.pth')\n",
    "\n",
    "\n",
    "if not skip_exec:\n",
    "    pruning_ffn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

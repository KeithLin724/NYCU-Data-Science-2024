{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer , T5ForConditionalGeneration,Seq2SeqTrainer,Seq2SeqTrainingArguments\n",
    "from transformers.models.t5.modeling_t5 import T5LayerSelfAttention , T5Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TALib import TALib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb751206f545a9af2a80ae9197c53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15159 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8d5df09cf94cd08efdd61c7cc43848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3790 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ta_lib = TALib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(TALib.TK_ckpt)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(TALib.CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(model=model , num_train_epochs=15 , batch_size=5 , output_dir=\"KY_billsum_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1412' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 26:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.49580979347229,\n",
       " 'eval_rouge1': 0.241,\n",
       " 'eval_rouge2': 0.1962,\n",
       " 'eval_rougeL': 0.2333,\n",
       " 'eval_rougeLsum': 0.2334,\n",
       " 'eval_gen_len': 18.9997,\n",
       " 'eval_runtime': 371.6962,\n",
       " 'eval_samples_per_second': 8.795,\n",
       " 'eval_steps_per_second': 1.76}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45480' max='45480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45480/45480 5:01:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.717000</td>\n",
       "      <td>1.461313</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.628100</td>\n",
       "      <td>1.441524</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>18.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.439500</td>\n",
       "      <td>1.427871</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.199400</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>18.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.567700</td>\n",
       "      <td>1.410927</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.237400</td>\n",
       "      <td>18.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.611700</td>\n",
       "      <td>1.403012</td>\n",
       "      <td>0.244800</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.665800</td>\n",
       "      <td>1.393306</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.380400</td>\n",
       "      <td>1.387831</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.493200</td>\n",
       "      <td>1.381272</td>\n",
       "      <td>0.245300</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.348400</td>\n",
       "      <td>1.376467</td>\n",
       "      <td>0.245200</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>0.238200</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>18.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.462200</td>\n",
       "      <td>1.372788</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.460100</td>\n",
       "      <td>1.368735</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.605100</td>\n",
       "      <td>1.366752</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.495800</td>\n",
       "      <td>1.364861</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.248000</td>\n",
       "      <td>1.364017</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.661900</td>\n",
       "      <td>1.364179</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45480, training_loss=1.5199361290340374, metrics={'train_runtime': 18094.4938, 'train_samples_per_second': 12.567, 'train_steps_per_second': 2.513, 'total_flos': 6.154939105542144e+16, 'train_loss': 1.5199361290340374, 'epoch': 15.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 06:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3625977039337158,\n",
       " 'eval_rouge1': 0.2448,\n",
       " 'eval_rouge2': 0.2024,\n",
       " 'eval_rougeL': 0.2379,\n",
       " 'eval_rougeLsum': 0.2379,\n",
       " 'eval_gen_len': 19.0,\n",
       " 'eval_runtime': 380.2154,\n",
       " 'eval_samples_per_second': 8.598,\n",
       " 'eval_steps_per_second': 1.72,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.t5.modeling_t5 import T5LayerSelfAttention, T5LayerCrossAttention, T5LayerFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = {\"self_attention\" : [] , \"cross_attention\":[] , \"ffn\":[] , \"lm_head\":[]}\n",
    "for name, module in model.named_modules():\n",
    "    # print(name , type(module))\n",
    "    if isinstance(module ,T5LayerSelfAttention ):\n",
    "        # print(\"SelfAttention \" , module)\n",
    "        \n",
    "        for name_2 , item in module.named_modules():\n",
    "            if isinstance(item , torch.nn.Linear):\n",
    "                parameters_to_prune[\"self_attention\"].append((item , \"weight\"))\n",
    "                \n",
    "    if isinstance(module ,T5LayerCrossAttention ):\n",
    "        # print(\"CrossAttention \" , module)\n",
    "        \n",
    "        for name_2 , item in module.named_modules():\n",
    "            if isinstance(item , torch.nn.Linear):\n",
    "                parameters_to_prune[\"cross_attention\"].append((item , \"weight\"))\n",
    "                \n",
    "    if isinstance(module ,T5LayerFF ):\n",
    "        # print(\"FFN \" , module)\n",
    "        \n",
    "        for name_2 , item in module.named_modules():\n",
    "            if isinstance(item , torch.nn.Linear):\n",
    "                parameters_to_prune[\"ffn\"].append((item , \"weight\"))\n",
    "                \n",
    "    if isinstance(module ,torch.nn.Linear ) and name == \"lm_head\":\n",
    "        parameters_to_prune[\"lm_head\"].append((module , \"weight\"))\n",
    "        \n",
    "    # if isinstance(module, torch.nn.Linear):\n",
    "    #     parameters_to_prune.append((module, \"weight\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attention': [(Linear(in_features=512, out_features=512, bias=False),\n",
       "   'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight')],\n",
       " 'cross_attention': [(Linear(in_features=512, out_features=512, bias=False),\n",
       "   'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=512, bias=False), 'weight')],\n",
       " 'ffn': [(Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight'),\n",
       "  (Linear(in_features=512, out_features=2048, bias=False), 'weight'),\n",
       "  (Linear(in_features=2048, out_features=512, bias=False), 'weight')],\n",
       " 'lm_head': [(Linear(in_features=512, out_features=32128, bias=False),\n",
       "   'weight')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention_prune_amount = 0.9\n",
    "cross_attention_prune_amount = 0.4\n",
    "ff_prune_amount = 0.7\n",
    "lm_head_amount = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(model=model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model():\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune[\"self_attention\"],\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=self_attention_prune_amount,\n",
    "    )\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune[\"cross_attention\"],\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=cross_attention_prune_amount,\n",
    "    )\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune[\"ffn\"],\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=ff_prune_amount,\n",
    "    )\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune[\"lm_head\"],\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=lm_head_amount,\n",
    "    )\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune[\"self_attention\"],\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=self_attention_prune_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128366470336914"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ta_lib.get_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1635' max='1635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1635/1635 12:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.7154033184051514,\n",
       " 'eval_rouge1': 0.039,\n",
       " 'eval_rouge2': 0.0055,\n",
       " 'eval_rougeL': 0.0343,\n",
       " 'eval_rougeLsum': 0.0343,\n",
       " 'eval_gen_len': 18.9376,\n",
       " 'eval_runtime': 777.4345,\n",
       " 'eval_samples_per_second': 4.205,\n",
       " 'eval_steps_per_second': 2.103}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ta_lib.get_trainer(model , num_train_epochs=15 , batch_size=5 ,output_dir=\"./output/pruning_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45480' max='45480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45480/45480 5:12:07, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.552600</td>\n",
       "      <td>2.214810</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>18.970400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.325900</td>\n",
       "      <td>2.081054</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>18.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.088200</td>\n",
       "      <td>2.019241</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>18.991800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.173100</td>\n",
       "      <td>1.966064</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>18.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.201100</td>\n",
       "      <td>1.934946</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>18.992600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.240900</td>\n",
       "      <td>1.904227</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>18.996600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.009100</td>\n",
       "      <td>1.887683</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>18.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.062400</td>\n",
       "      <td>1.872282</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>18.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.905300</td>\n",
       "      <td>1.858434</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>18.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.008100</td>\n",
       "      <td>1.851333</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.959100</td>\n",
       "      <td>1.840119</td>\n",
       "      <td>0.240800</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>18.998400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.161100</td>\n",
       "      <td>1.835456</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.008200</td>\n",
       "      <td>1.830501</td>\n",
       "      <td>0.240700</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.811000</td>\n",
       "      <td>1.828611</td>\n",
       "      <td>0.240600</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>18.997900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.185500</td>\n",
       "      <td>1.827360</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.232900</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>18.997400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45480, training_loss=2.1489335898044555, metrics={'train_runtime': 18728.5176, 'train_samples_per_second': 12.141, 'train_steps_per_second': 2.428, 'total_flos': 6.154939105542144e+16, 'train_loss': 2.1489335898044555, 'epoch': 15.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 06:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.8115092515945435,\n",
       " 'eval_rouge1': 0.2391,\n",
       " 'eval_rouge2': 0.1938,\n",
       " 'eval_rougeL': 0.2311,\n",
       " 'eval_rougeLsum': 0.2311,\n",
       " 'eval_gen_len': 18.9969,\n",
       " 'eval_runtime': 372.1457,\n",
       " 'eval_samples_per_second': 8.784,\n",
       " 'eval_steps_per_second': 1.757,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128366470336914"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune[\"cross_attention\"],\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=cross_attention_prune_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712448239326477"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(model , num_train_epochs=20 , batch_size=5 ,output_dir=\"./output/pruning_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1412' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 27:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.325265407562256,\n",
       " 'eval_rouge1': 0.0139,\n",
       " 'eval_rouge2': 0.0001,\n",
       " 'eval_rougeL': 0.0137,\n",
       " 'eval_rougeLsum': 0.0137,\n",
       " 'eval_gen_len': 18.4628,\n",
       " 'eval_runtime': 386.4415,\n",
       " 'eval_samples_per_second': 8.459,\n",
       " 'eval_steps_per_second': 1.692}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60640' max='60640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60640/60640 6:50:51, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.937200</td>\n",
       "      <td>2.497152</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>18.906100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.626800</td>\n",
       "      <td>2.276995</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>18.954100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.359500</td>\n",
       "      <td>2.180384</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.218700</td>\n",
       "      <td>0.218700</td>\n",
       "      <td>18.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.424400</td>\n",
       "      <td>2.134937</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>0.222300</td>\n",
       "      <td>18.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.440600</td>\n",
       "      <td>2.099964</td>\n",
       "      <td>0.233500</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>18.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.463400</td>\n",
       "      <td>2.067773</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>18.992600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.249200</td>\n",
       "      <td>2.049789</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.186100</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>18.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.272700</td>\n",
       "      <td>2.036448</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.226900</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>18.996600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.139800</td>\n",
       "      <td>2.015613</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.227400</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>18.997100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.201200</td>\n",
       "      <td>2.005004</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.156000</td>\n",
       "      <td>1.989868</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.318900</td>\n",
       "      <td>1.986740</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>18.997400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>1.975237</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>18.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.029400</td>\n",
       "      <td>1.969652</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.334200</td>\n",
       "      <td>1.965500</td>\n",
       "      <td>0.238300</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.096300</td>\n",
       "      <td>1.959816</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.238000</td>\n",
       "      <td>1.955960</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.190600</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.152300</td>\n",
       "      <td>1.956412</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>18.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.074400</td>\n",
       "      <td>1.952657</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>18.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.149800</td>\n",
       "      <td>1.952919</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>18.995000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60640, training_loss=2.3469779018990913, metrics={'train_runtime': 24651.7094, 'train_samples_per_second': 12.299, 'train_steps_per_second': 2.46, 'total_flos': 8.206585474056192e+16, 'train_loss': 2.3469779018990913, 'epoch': 20.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 06:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.9339864253997803,\n",
       " 'eval_rouge1': 0.238,\n",
       " 'eval_rouge2': 0.1907,\n",
       " 'eval_rougeL': 0.2293,\n",
       " 'eval_rougeLsum': 0.2294,\n",
       " 'eval_gen_len': 18.9939,\n",
       " 'eval_runtime': 380.9624,\n",
       " 'eval_samples_per_second': 8.581,\n",
       " 'eval_steps_per_second': 1.717,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune[\"ffn\"],\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=ff_prune_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48010188341140747"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(model , num_train_epochs=15 , batch_size=5 ,output_dir=\"./output/pruning_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1412' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 30:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.28693962097168,\n",
       " 'eval_rouge1': 0.0146,\n",
       " 'eval_rouge2': 0.0001,\n",
       " 'eval_rougeL': 0.0146,\n",
       " 'eval_rougeLsum': 0.0146,\n",
       " 'eval_gen_len': 19.0,\n",
       " 'eval_runtime': 392.3616,\n",
       " 'eval_samples_per_second': 8.332,\n",
       " 'eval_steps_per_second': 1.667}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45480' max='45480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45480/45480 5:26:48, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.086800</td>\n",
       "      <td>2.531628</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>18.948500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.843200</td>\n",
       "      <td>2.433920</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>0.216000</td>\n",
       "      <td>18.990800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.588100</td>\n",
       "      <td>2.386825</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>18.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.689200</td>\n",
       "      <td>2.349193</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>18.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.732400</td>\n",
       "      <td>2.324470</td>\n",
       "      <td>0.230800</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>18.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.734000</td>\n",
       "      <td>2.302664</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>18.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.572900</td>\n",
       "      <td>2.287221</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>18.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.583400</td>\n",
       "      <td>2.277168</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>18.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.410300</td>\n",
       "      <td>2.261664</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.224100</td>\n",
       "      <td>18.992300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.518400</td>\n",
       "      <td>2.256471</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.460500</td>\n",
       "      <td>2.246699</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225100</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.681500</td>\n",
       "      <td>2.244034</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.511800</td>\n",
       "      <td>2.238776</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.354100</td>\n",
       "      <td>2.236782</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.688600</td>\n",
       "      <td>2.235728</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>18.998200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=45480, training_loss=2.6936071073369385, metrics={'train_runtime': 19609.6108, 'train_samples_per_second': 11.596, 'train_steps_per_second': 2.319, 'total_flos': 6.154939105542144e+16, 'train_loss': 2.6936071073369385, 'epoch': 15.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 06:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.212543249130249,\n",
       " 'eval_rouge1': 0.2343,\n",
       " 'eval_rouge2': 0.1853,\n",
       " 'eval_rougeL': 0.2254,\n",
       " 'eval_rougeLsum': 0.2253,\n",
       " 'eval_gen_len': 18.9951,\n",
       " 'eval_runtime': 400.8947,\n",
       " 'eval_samples_per_second': 8.154,\n",
       " 'eval_steps_per_second': 1.631,\n",
       " 'epoch': 15.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune[\"lm_head\"],\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=lm_head_amount,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26261115074157715"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(model , num_train_epochs=30 , batch_size=5 ,output_dir=\"./output/pruning_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1412' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 28:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.514431476593018,\n",
       " 'eval_rouge1': 0.051,\n",
       " 'eval_rouge2': 0.0224,\n",
       " 'eval_rougeL': 0.0493,\n",
       " 'eval_rougeLsum': 0.0493,\n",
       " 'eval_gen_len': 18.6164,\n",
       " 'eval_runtime': 388.3105,\n",
       " 'eval_samples_per_second': 8.419,\n",
       " 'eval_steps_per_second': 1.684}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='90960' max='90960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [90960/90960 11:07:26, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.002100</td>\n",
       "      <td>4.273895</td>\n",
       "      <td>0.122600</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>18.964900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.291200</td>\n",
       "      <td>3.746312</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>18.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.858700</td>\n",
       "      <td>3.498810</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>18.959100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.912800</td>\n",
       "      <td>3.349042</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>18.935400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.908200</td>\n",
       "      <td>3.247055</td>\n",
       "      <td>0.211700</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>18.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.855600</td>\n",
       "      <td>3.164701</td>\n",
       "      <td>0.214400</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>18.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.588700</td>\n",
       "      <td>3.108447</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>18.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.578100</td>\n",
       "      <td>3.059389</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>18.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.387000</td>\n",
       "      <td>3.010522</td>\n",
       "      <td>0.223500</td>\n",
       "      <td>0.171500</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>18.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.496100</td>\n",
       "      <td>2.977571</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.216700</td>\n",
       "      <td>18.973900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.397200</td>\n",
       "      <td>2.947351</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>18.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3.649300</td>\n",
       "      <td>2.921451</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.176200</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>18.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3.431300</td>\n",
       "      <td>2.898324</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>18.978400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.202300</td>\n",
       "      <td>2.881674</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>18.982100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>3.595600</td>\n",
       "      <td>2.864382</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>18.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>3.221000</td>\n",
       "      <td>2.846140</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.223300</td>\n",
       "      <td>18.983400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>3.415000</td>\n",
       "      <td>2.833377</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>0.223700</td>\n",
       "      <td>18.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>3.267800</td>\n",
       "      <td>2.821961</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>18.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>3.127000</td>\n",
       "      <td>2.809026</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.224700</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>18.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.233200</td>\n",
       "      <td>2.802181</td>\n",
       "      <td>0.234200</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>18.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>3.291400</td>\n",
       "      <td>2.790891</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>18.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>3.416100</td>\n",
       "      <td>2.784611</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.225100</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>18.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>3.458200</td>\n",
       "      <td>2.779281</td>\n",
       "      <td>0.234100</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.225300</td>\n",
       "      <td>18.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>3.459900</td>\n",
       "      <td>2.775924</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.183000</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>18.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>3.456500</td>\n",
       "      <td>2.767764</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>18.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>3.507800</td>\n",
       "      <td>2.766650</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>18.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.973700</td>\n",
       "      <td>2.765269</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.183400</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>18.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>3.388100</td>\n",
       "      <td>2.761266</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>18.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>3.113600</td>\n",
       "      <td>2.761467</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>18.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.041300</td>\n",
       "      <td>2.761223</td>\n",
       "      <td>0.234600</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>18.989200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90960, training_loss=3.5635117952091817, metrics={'train_runtime': 40046.5942, 'train_samples_per_second': 11.356, 'train_steps_per_second': 2.271, 'total_flos': 1.2309878211084288e+17, 'train_loss': 3.5635117952091817, 'epoch': 30.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.7338263988494873,\n",
       " 'eval_rouge1': 0.2343,\n",
       " 'eval_rouge2': 0.1838,\n",
       " 'eval_rougeL': 0.2253,\n",
       " 'eval_rougeLsum': 0.2253,\n",
       " 'eval_gen_len': 18.9838,\n",
       " 'eval_runtime': 389.4141,\n",
       " 'eval_samples_per_second': 8.395,\n",
       " 'eval_steps_per_second': 1.679,\n",
       " 'epoch': 30.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26261115074157715"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.predict(ta_lib.tokenized_billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_prediction = ta_lib.tokenizer.batch_decode(results[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amends the Water Resources Development Act of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Federal Forage Fee Act of 1993 - Amends the Fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Merchant Marine of World War II Congressional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Small Business Tax Modernization Act of 2004 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Fair Access to Investment Research Act of 2016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>3264</td>\n",
       "      <td>Public Servant Priority Placement Act of 1995 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>3265</td>\n",
       "      <td>Sportsmanship of 2008 - Amends the Federal cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>3266</td>\n",
       "      <td>Helping College Student Cross the Finish Line ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>3267</td>\n",
       "      <td>Texas National Forests Improvement Act of 2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>3268</td>\n",
       "      <td>Federal Power Asset Privatization Act of 1995 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3269 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                            Predict\n",
       "0        0  Amends the Water Resources Development Act of ...\n",
       "1        1  Federal Forage Fee Act of 1993 - Amends the Fe...\n",
       "2        2  Merchant Marine of World War II Congressional ...\n",
       "3        3  Small Business Tax Modernization Act of 2004 -...\n",
       "4        4  Fair Access to Investment Research Act of 2016...\n",
       "...    ...                                                ...\n",
       "3264  3264  Public Servant Priority Placement Act of 1995 ...\n",
       "3265  3265  Sportsmanship of 2008 - Amends the Federal cri...\n",
       "3266  3266  Helping College Student Cross the Finish Line ...\n",
       "3267  3267  Texas National Forests Improvement Act of 2000...\n",
       "3268  3268  Federal Power Asset Privatization Act of 1995 ...\n",
       "\n",
       "[3269 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.dump_to_kaggle_format(decoded_prediction , 'pruned_model_0.26_day_5_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16520012803386583"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.run_score(decoded_prediction , ta_lib.billsum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TALib.save_model(model , \"output/pruning_success_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at output/pruning_success_v2 were not used when initializing T5ForConditionalGeneration: ['decoder.block.0.layer.0.SelfAttention.k.weight_mask', 'decoder.block.0.layer.0.SelfAttention.k.weight_orig', 'decoder.block.0.layer.0.SelfAttention.o.weight_mask', 'decoder.block.0.layer.0.SelfAttention.o.weight_orig', 'decoder.block.0.layer.0.SelfAttention.q.weight_mask', 'decoder.block.0.layer.0.SelfAttention.q.weight_orig', 'decoder.block.0.layer.0.SelfAttention.v.weight_mask', 'decoder.block.0.layer.0.SelfAttention.v.weight_orig', 'decoder.block.0.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.0.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.0.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.0.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.0.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.0.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.0.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.0.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.0.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.0.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.0.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.0.layer.2.DenseReluDense.wo.weight_orig', 'decoder.block.1.layer.0.SelfAttention.k.weight_mask', 'decoder.block.1.layer.0.SelfAttention.k.weight_orig', 'decoder.block.1.layer.0.SelfAttention.o.weight_mask', 'decoder.block.1.layer.0.SelfAttention.o.weight_orig', 'decoder.block.1.layer.0.SelfAttention.q.weight_mask', 'decoder.block.1.layer.0.SelfAttention.q.weight_orig', 'decoder.block.1.layer.0.SelfAttention.v.weight_mask', 'decoder.block.1.layer.0.SelfAttention.v.weight_orig', 'decoder.block.1.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.1.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.1.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.1.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.1.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.1.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.1.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.1.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.1.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.1.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.1.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.1.layer.2.DenseReluDense.wo.weight_orig', 'decoder.block.2.layer.0.SelfAttention.k.weight_mask', 'decoder.block.2.layer.0.SelfAttention.k.weight_orig', 'decoder.block.2.layer.0.SelfAttention.o.weight_mask', 'decoder.block.2.layer.0.SelfAttention.o.weight_orig', 'decoder.block.2.layer.0.SelfAttention.q.weight_mask', 'decoder.block.2.layer.0.SelfAttention.q.weight_orig', 'decoder.block.2.layer.0.SelfAttention.v.weight_mask', 'decoder.block.2.layer.0.SelfAttention.v.weight_orig', 'decoder.block.2.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.2.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.2.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.2.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.2.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.2.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.2.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.2.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.2.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.2.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.2.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.2.layer.2.DenseReluDense.wo.weight_orig', 'decoder.block.3.layer.0.SelfAttention.k.weight_mask', 'decoder.block.3.layer.0.SelfAttention.k.weight_orig', 'decoder.block.3.layer.0.SelfAttention.o.weight_mask', 'decoder.block.3.layer.0.SelfAttention.o.weight_orig', 'decoder.block.3.layer.0.SelfAttention.q.weight_mask', 'decoder.block.3.layer.0.SelfAttention.q.weight_orig', 'decoder.block.3.layer.0.SelfAttention.v.weight_mask', 'decoder.block.3.layer.0.SelfAttention.v.weight_orig', 'decoder.block.3.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.3.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.3.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.3.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.3.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.3.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.3.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.3.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.3.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.3.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.3.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.3.layer.2.DenseReluDense.wo.weight_orig', 'decoder.block.4.layer.0.SelfAttention.k.weight_mask', 'decoder.block.4.layer.0.SelfAttention.k.weight_orig', 'decoder.block.4.layer.0.SelfAttention.o.weight_mask', 'decoder.block.4.layer.0.SelfAttention.o.weight_orig', 'decoder.block.4.layer.0.SelfAttention.q.weight_mask', 'decoder.block.4.layer.0.SelfAttention.q.weight_orig', 'decoder.block.4.layer.0.SelfAttention.v.weight_mask', 'decoder.block.4.layer.0.SelfAttention.v.weight_orig', 'decoder.block.4.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.4.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.4.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.4.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.4.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.4.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.4.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.4.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.4.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.4.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.4.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.4.layer.2.DenseReluDense.wo.weight_orig', 'decoder.block.5.layer.0.SelfAttention.k.weight_mask', 'decoder.block.5.layer.0.SelfAttention.k.weight_orig', 'decoder.block.5.layer.0.SelfAttention.o.weight_mask', 'decoder.block.5.layer.0.SelfAttention.o.weight_orig', 'decoder.block.5.layer.0.SelfAttention.q.weight_mask', 'decoder.block.5.layer.0.SelfAttention.q.weight_orig', 'decoder.block.5.layer.0.SelfAttention.v.weight_mask', 'decoder.block.5.layer.0.SelfAttention.v.weight_orig', 'decoder.block.5.layer.1.EncDecAttention.k.weight_mask', 'decoder.block.5.layer.1.EncDecAttention.k.weight_orig', 'decoder.block.5.layer.1.EncDecAttention.o.weight_mask', 'decoder.block.5.layer.1.EncDecAttention.o.weight_orig', 'decoder.block.5.layer.1.EncDecAttention.q.weight_mask', 'decoder.block.5.layer.1.EncDecAttention.q.weight_orig', 'decoder.block.5.layer.1.EncDecAttention.v.weight_mask', 'decoder.block.5.layer.1.EncDecAttention.v.weight_orig', 'decoder.block.5.layer.2.DenseReluDense.wi.weight_mask', 'decoder.block.5.layer.2.DenseReluDense.wi.weight_orig', 'decoder.block.5.layer.2.DenseReluDense.wo.weight_mask', 'decoder.block.5.layer.2.DenseReluDense.wo.weight_orig', 'encoder.block.0.layer.0.SelfAttention.k.weight_mask', 'encoder.block.0.layer.0.SelfAttention.k.weight_orig', 'encoder.block.0.layer.0.SelfAttention.o.weight_mask', 'encoder.block.0.layer.0.SelfAttention.o.weight_orig', 'encoder.block.0.layer.0.SelfAttention.q.weight_mask', 'encoder.block.0.layer.0.SelfAttention.q.weight_orig', 'encoder.block.0.layer.0.SelfAttention.v.weight_mask', 'encoder.block.0.layer.0.SelfAttention.v.weight_orig', 'encoder.block.0.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.0.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.0.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.0.layer.1.DenseReluDense.wo.weight_orig', 'encoder.block.1.layer.0.SelfAttention.k.weight_mask', 'encoder.block.1.layer.0.SelfAttention.k.weight_orig', 'encoder.block.1.layer.0.SelfAttention.o.weight_mask', 'encoder.block.1.layer.0.SelfAttention.o.weight_orig', 'encoder.block.1.layer.0.SelfAttention.q.weight_mask', 'encoder.block.1.layer.0.SelfAttention.q.weight_orig', 'encoder.block.1.layer.0.SelfAttention.v.weight_mask', 'encoder.block.1.layer.0.SelfAttention.v.weight_orig', 'encoder.block.1.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.1.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.1.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.1.layer.1.DenseReluDense.wo.weight_orig', 'encoder.block.2.layer.0.SelfAttention.k.weight_mask', 'encoder.block.2.layer.0.SelfAttention.k.weight_orig', 'encoder.block.2.layer.0.SelfAttention.o.weight_mask', 'encoder.block.2.layer.0.SelfAttention.o.weight_orig', 'encoder.block.2.layer.0.SelfAttention.q.weight_mask', 'encoder.block.2.layer.0.SelfAttention.q.weight_orig', 'encoder.block.2.layer.0.SelfAttention.v.weight_mask', 'encoder.block.2.layer.0.SelfAttention.v.weight_orig', 'encoder.block.2.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.2.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.2.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.2.layer.1.DenseReluDense.wo.weight_orig', 'encoder.block.3.layer.0.SelfAttention.k.weight_mask', 'encoder.block.3.layer.0.SelfAttention.k.weight_orig', 'encoder.block.3.layer.0.SelfAttention.o.weight_mask', 'encoder.block.3.layer.0.SelfAttention.o.weight_orig', 'encoder.block.3.layer.0.SelfAttention.q.weight_mask', 'encoder.block.3.layer.0.SelfAttention.q.weight_orig', 'encoder.block.3.layer.0.SelfAttention.v.weight_mask', 'encoder.block.3.layer.0.SelfAttention.v.weight_orig', 'encoder.block.3.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.3.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.3.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.3.layer.1.DenseReluDense.wo.weight_orig', 'encoder.block.4.layer.0.SelfAttention.k.weight_mask', 'encoder.block.4.layer.0.SelfAttention.k.weight_orig', 'encoder.block.4.layer.0.SelfAttention.o.weight_mask', 'encoder.block.4.layer.0.SelfAttention.o.weight_orig', 'encoder.block.4.layer.0.SelfAttention.q.weight_mask', 'encoder.block.4.layer.0.SelfAttention.q.weight_orig', 'encoder.block.4.layer.0.SelfAttention.v.weight_mask', 'encoder.block.4.layer.0.SelfAttention.v.weight_orig', 'encoder.block.4.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.4.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.4.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.4.layer.1.DenseReluDense.wo.weight_orig', 'encoder.block.5.layer.0.SelfAttention.k.weight_mask', 'encoder.block.5.layer.0.SelfAttention.k.weight_orig', 'encoder.block.5.layer.0.SelfAttention.o.weight_mask', 'encoder.block.5.layer.0.SelfAttention.o.weight_orig', 'encoder.block.5.layer.0.SelfAttention.q.weight_mask', 'encoder.block.5.layer.0.SelfAttention.q.weight_orig', 'encoder.block.5.layer.0.SelfAttention.v.weight_mask', 'encoder.block.5.layer.0.SelfAttention.v.weight_orig', 'encoder.block.5.layer.1.DenseReluDense.wi.weight_mask', 'encoder.block.5.layer.1.DenseReluDense.wi.weight_orig', 'encoder.block.5.layer.1.DenseReluDense.wo.weight_mask', 'encoder.block.5.layer.1.DenseReluDense.wo.weight_orig', 'lm_head.weight_mask']\n",
      "- This IS expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5ForConditionalGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at output/pruning_success_v2 and are newly initialized: ['decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.1.DenseReluDense.wi.weight', 'encoder.block.0.layer.1.DenseReluDense.wo.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.1.DenseReluDense.wi.weight', 'encoder.block.1.layer.1.DenseReluDense.wo.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.2.layer.1.DenseReluDense.wi.weight', 'encoder.block.2.layer.1.DenseReluDense.wo.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.1.DenseReluDense.wi.weight', 'encoder.block.3.layer.1.DenseReluDense.wo.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.1.DenseReluDense.wi.weight', 'encoder.block.4.layer.1.DenseReluDense.wo.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.1.DenseReluDense.wi.weight', 'encoder.block.5.layer.1.DenseReluDense.wo.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "reload_model = TALib.load_model(\"output/pruning_success_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26261115074157715"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TALib.show_param_ratio(reload_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ta_lib.get_trainer(reload_model , num_train_epochs=30 , batch_size=5 ,output_dir=\"./output/pruning_check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code/python/NYCU-Data-Science-2024/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='654' max='654' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [654/654 07:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.7338263988494873,\n",
       " 'eval_rouge1': 0.2343,\n",
       " 'eval_rouge2': 0.1838,\n",
       " 'eval_rougeL': 0.2253,\n",
       " 'eval_rougeLsum': 0.2253,\n",
       " 'eval_gen_len': 18.9838,\n",
       " 'eval_runtime': 431.505,\n",
       " 'eval_samples_per_second': 7.576,\n",
       " 'eval_steps_per_second': 1.516}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(ta_lib.tokenized_billsum_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
